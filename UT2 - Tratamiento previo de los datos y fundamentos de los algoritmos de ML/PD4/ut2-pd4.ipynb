{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this exercise we will be processing messy data from the popular \"Titanic\" dataset (taken from Kaggle), so that it is ready to use for bulding a model that can predict whether a given passenger survived or not. This process is based on the one found here: https://www.kaggle.com/samsonqian/titanic-guide-with-sklearn-and-eda\n\nFirst we need to import the data, as well as the libraries we will be using. Numpy and Pandas will help us manipulate the data, and matplotlib and Seaborn will help us visualize it."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nsns.set_style(\"whitegrid\")\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ntraining = pd.read_csv(\"../input/titanic/train.csv\")\ntesting = pd.read_csv(\"../input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using Pandas we can take a look at some of the data we will be processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"training.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see right away that there seems to be a lot of missing values in the data, especially for the Cabin column. We need to check the rest of the dataset to see just how much data is missing, and then see what we can do to replace it. That way the model can have a complete prediction for every row in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"def null_table(training, testing):\n    print(\"---Training---\")\n    print(pd.isnull(training).sum()) \n    print(\" \")\n    print(\"---Testing---\")\n    print(pd.isnull(testing).sum())\n\nnull_table(training, testing)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thankfully the missing values seem to be contained to just two of the columns. Given how few values for Cabin there are in the dataset, it would be a good idea to just drop that column altogether. After all, it's probably highly correlated with the passenger's class or fare. While we're dropping attributes, we might as well do the same for Ticket, since the number appears to be pretty much random and it will likely throw off the model. \n\nFor the Age, we will need to take a look at its distribution to decide what to replace the missing values with"},{"metadata":{"trusted":true},"cell_type":"code","source":"copy = training.copy()\ncopy.dropna(inplace = True)\nsns.distplot(copy[\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the distribution is a bit skewed, it would be best to replace the missing values with the median age. Having the values lean towards one end greatly impacts the mean, making it a less accurate replacement in this case."},{"metadata":{"trusted":true},"cell_type":"code","source":"training.drop(labels = [\"Cabin\", \"Ticket\"], axis = 1, inplace = True)\ntesting.drop(labels = [\"Cabin\", \"Ticket\"], axis = 1, inplace = True)\n\ntraining[\"Age\"].fillna(training[\"Age\"].median(), inplace = True)\ntesting[\"Age\"].fillna(testing[\"Age\"].median(), inplace = True) \ntraining[\"Embarked\"].fillna(\"S\", inplace = True)\ntesting[\"Fare\"].fillna(testing[\"Fare\"].median(), inplace = True)\n\nnull_table(training, testing)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before making any more modifications to our data, it would be a good idea to try and put it into charts so we can visualize it. Doing so might help us identify which attributes have the largest impact on whether the passenger survived or not. For example, let's take a look at the gender:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"Sex\", y=\"Survived\", data=training)\nplt.title(\"Distribution of Survival based on Gender\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, the survivors were mostly women instead of men, likely due to the classic \"women and children first\" rule. This can also be seen in the distribution of survival based on age:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.stripplot(x=\"Survived\", y=\"Age\", data=training, jitter=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This one is closer, but we can still distinguish some clustering of passengers at the bottom of the right strip, meaning that younger passengers were more likely to survive.\n\nLet's take a look at one more example with passengers' class:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"Pclass\", y=\"Survived\", data=training)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Distribution of Survival Based on Class\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This one shows us that higher-class passengers were more likely to survive than lower-class passengers, which again, shouldn't be too surprising."},{"metadata":{},"cell_type":"markdown","source":"Next we need to make sure that all of our atributes are numerical, since it is required for most classification models. The attributes Name, Sex and Embarked are the only ones that are not numerical. Sex and Embarked are categorical, meaning that they can easily be transformed by assigning a number to each posible value they can have."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle_sex = LabelEncoder()\nle_sex.fit(training[\"Sex\"])\n\nencoded_sex_training = le_sex.transform(training[\"Sex\"])\ntraining[\"Sex\"] = encoded_sex_training\nencoded_sex_testing = le_sex.transform(testing[\"Sex\"])\ntesting[\"Sex\"] = encoded_sex_testing\n\nle_embarked = LabelEncoder()\nle_embarked.fit(training[\"Embarked\"])\n\nencoded_embarked_training = le_embarked.transform(training[\"Embarked\"])\ntraining[\"Embarked\"] = encoded_embarked_training\nencoded_embarked_testing = le_embarked.transform(testing[\"Embarked\"])\ntesting[\"Embarked\"] = encoded_embarked_testing\n\ntraining.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Name column might seem like it could be dropped, but we can still take some useful information out of it. Many of the passengers have titles (like \"Mr, Miss, Capt, etc.) which might help predict their survival. We can take these titles and turn them into a categorical attribute, and then to a numeric one, like with the previous two attributes."},{"metadata":{"trusted":true},"cell_type":"code","source":"for name in training[\"Name\"]:\n    training[\"Title\"] = training[\"Name\"].str.extract(\"([A-Za-z]+)\\.\",expand=True)\n    \nfor name in testing[\"Name\"]:\n    testing[\"Title\"] = testing[\"Name\"].str.extract(\"([A-Za-z]+)\\.\",expand=True)\n\ntitles = set(training[\"Title\"])\ntitle_list = list(training[\"Title\"])\nfrequency_titles = []\n\nfor i in titles:\n    frequency_titles.append(title_list.count(i))\n\ntitles = list(titles)\n\ntitle_dataframe = pd.DataFrame({\n    \"Titles\" : titles,\n    \"Frequency\" : frequency_titles\n})\n\nprint(title_dataframe)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like there were 17 different titles in there. Now that we now what they all are, we just need to assign a number to each one."},{"metadata":{"trusted":true},"cell_type":"code","source":"title_replacements = {\"Mlle\": \"Other\", \"Major\": \"Other\", \"Col\": \"Other\", \"Sir\": \"Other\", \"Don\": \"Other\", \"Mme\": \"Other\",\n          \"Jonkheer\": \"Other\", \"Lady\": \"Other\", \"Capt\": \"Other\", \"Countess\": \"Other\", \"Ms\": \"Other\", \"Dona\": \"Other\"}\n\ntraining.replace({\"Title\": title_replacements}, inplace=True)\ntesting.replace({\"Title\": title_replacements}, inplace=True)\n\nle_title = LabelEncoder()\nle_title.fit(training[\"Title\"])\n\nencoded_title_training = le_title.transform(training[\"Title\"])\ntraining[\"Title\"] = encoded_title_training\nencoded_title_testing = le_title.transform(testing[\"Title\"])\ntesting[\"Title\"] = encoded_title_testing\n\ntraining.drop(\"Name\", axis = 1, inplace = True)\ntesting.drop(\"Name\", axis = 1, inplace = True)\n\ntraining.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One more thing we can do before the final preprocessing step is to combine SibSp (number of siblings/spouses aboard) and Parch (number of parents/children aboard). These two attributes might not seem too impactful on their own, but together they determine the total amount of family members aboard for each passenger, which might be a bit more significant."},{"metadata":{"trusted":true},"cell_type":"code","source":"training[\"FamSize\"] = training[\"SibSp\"] + training[\"Parch\"] + 1\ntesting[\"FamSize\"] = testing[\"SibSp\"] + testing[\"Parch\"] + 1\n\ntraining.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The last preprocessing task we have left is scaling the data. We can see that the Age and Fare attributes above deviate too much from the values in the other columns. Some modelling techniques rely on calculating distance between examples in order to properly classify them, and this difference in ranges would heavily impact their performance. It would be better to scale these values so that they are in line wit the ranges of the other attributes."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nages_train = np.array(training[\"Age\"]).reshape(-1, 1)\nfares_train = np.array(training[\"Fare\"]).reshape(-1, 1)\nages_test = np.array(testing[\"Age\"]).reshape(-1, 1)\nfares_test = np.array(testing[\"Fare\"]).reshape(-1, 1)\n\ntraining[\"Age\"] = scaler.fit_transform(ages_train)\ntraining[\"Fare\"] = scaler.fit_transform(fares_train)\ntesting[\"Age\"] = scaler.fit_transform(ages_test)\ntesting[\"Fare\"] = scaler.fit_transform(fares_test)\n\ntraining.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With all that done, the data is now finally ready for modelling."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}